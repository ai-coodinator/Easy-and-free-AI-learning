{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"augmentation_image_recognition.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"a_GkibcbD930"},"source":["# **Teaching materials for AI beginners**  \n","**augmentation_image_recognition**  \n","Let's create an AI model with the prepared image.\n","Once you can do this, you will be able to create your own image classification model.  \n","And this code is a code that can be expected to improve the accuracy by amplifying the learning image.\n","We prepared 10 classes of 50 images for each class.  \n","'camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch'  \n","The more images you have, the higher the accuracy.  \n","You can also try changing to the collected image.\n","Just put the images in a folder.\n","It's very easy. Try it with your own image.  "]},{"cell_type":"markdown","metadata":{"id":"csAW4DCxFMtk"},"source":["##1.Development environment preparation"]},{"cell_type":"markdown","metadata":{"id":"vpQazSrIxkMD"},"source":["###1-1.Connect to Google Drive."]},{"cell_type":"code","metadata":{"id":"5winc0172fJa","executionInfo":{"status":"ok","timestamp":1604222878368,"user_tz":-540,"elapsed":25254,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"a16d2c5e-9f59-41d9-e81c-6d63523efcee","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"426PZy36FYj2"},"source":["###1-2.Go to My Drive."]},{"cell_type":"code","metadata":{"id":"2Fzfjaol3WPF","executionInfo":{"status":"ok","timestamp":1604222878368,"user_tz":-540,"elapsed":25250,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"c0353e17-c649-4860-fd70-cc6bdf990de9","colab":{"base_uri":"https://localhost:8080/"}},"source":["cd /content/gdrive/My\\ Drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2nAwjalfFkaw"},"source":["###1-3.Download the code from github."]},{"cell_type":"code","metadata":{"id":"n0v4WDGf4FkO","executionInfo":{"status":"ok","timestamp":1604222889749,"user_tz":-540,"elapsed":36628,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"fa676cea-d864-4663-acc5-1a4db3fbaa0e","colab":{"base_uri":"https://localhost:8080/"}},"source":["!git clone https://github.com/ai-coodinator/Easy-and-free-AI-learning.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'Easy-and-free-AI-learning'...\n","remote: Enumerating objects: 4, done.\u001b[K\n","remote: Counting objects: 100% (4/4), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 948 (delta 0), reused 0 (delta 0), pack-reused 944\u001b[K\n","Receiving objects: 100% (948/948), 7.55 MiB | 13.93 MiB/s, done.\n","Resolving deltas: 100% (167/167), done.\n","Checking out files: 100% (1043/1043), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iPtl8d5UFtUg"},"source":["##1-4.Change to the downloaded directory."]},{"cell_type":"code","metadata":{"id":"g4bhPxFs4JHx","executionInfo":{"status":"ok","timestamp":1604222889751,"user_tz":-540,"elapsed":36627,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"fe1a311e-82f7-4f9f-813c-c0eb61ebb056","colab":{"base_uri":"https://localhost:8080/"}},"source":["cd Easy-and-free-AI-learning/04_augmentation_image_recognition/"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Easy-and-free-AI-learning/04_augmentation_image_recognition\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ad08kRkN275z"},"source":["##1-5.Confirmation of GPU to use"]},{"cell_type":"code","metadata":{"id":"2M0hIVoy20UN","executionInfo":{"status":"ok","timestamp":1604222889751,"user_tz":-540,"elapsed":36624,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"1448aa07-3fd4-4199-c776-fc9adcf3aea4","colab":{"base_uri":"https://localhost:8080/"}},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Sun Nov  1 09:28:09 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m5gmIjCyzuoo"},"source":["##2.Data creation for learning  \n","This code transforms the prepared image data into a single training dataset.  \n","It is also a code that amplifies the image to increase the number of learnings. Increase the number of images while changing the angle of the images. Also, transpose the image to increase the number of images.  \n","If you want to change or add training data, make the folder a class and place it in the Image folder."]},{"cell_type":"code","metadata":{"id":"qzyaQx424xU0","executionInfo":{"status":"ok","timestamp":1604222902131,"user_tz":-540,"elapsed":49001,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"737f4681-3d38-495c-e657-e261336ada70","colab":{"base_uri":"https://localhost:8080/"}},"source":["from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import os, glob\n","import numpy as np\n","import random, math\n","\n","# read image\n","root_dir = \"./image/\"\n","directory = os.listdir(root_dir)\n","categories = [f for f in directory if os.path.isdir(os.path.join(root_dir, f))]\n","print(categories)\n","\n","num_classes = len(categories)\n","\n","# resize\n","image_size = 224\n","\n","# make image dataset\n","X = [] # image\n","Y = [] # label\n","\n","# read image\n","for idx, cat in enumerate(categories):\n","\n","    label = [0 for i in range(num_classes)]\n","    label[idx] = 1\n","\n","    image_dir = root_dir + \"/\" + cat\n","    files = glob.glob(image_dir + \"/*.jpg\")\n","    for i, f in enumerate(files):\n","        img = Image.open(f)\n","        img = img.convert(\"RGB\")\n","        img = img.resize((image_size, image_size))\n","        data = np.asarray(img)\n","        X.append(data)\n","        Y.append(label)\n","\n","        # Data Augmentation\n","        for ang in range(-20, 20, 5):\n","            img2 = img.rotate(ang)\n","            data = np.asarray(img2)\n","            X.append(data)\n","            Y.append(label)\n","\n","            # transpose data\n","            img2 = img2.transpose(Image.FLIP_LEFT_RIGHT)\n","            data = np.asarray(img2)\n","            X.append(data)\n","            Y.append(label)\n","\n","X = np.array(X)\n","Y = np.array(Y)\n","\n","# make npy\n","X_train, X_test, y_train, y_test = \\\n","    train_test_split(X, Y, test_size=0.2)\n","xy = (X_train, X_test, y_train, y_test)\n","np.save(\"./image/\" + \"obj.npy\", xy)\n","\n","print(\"ok,\", len(X_train), len(X_test))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["['camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch']\n","ok, 6800 1700\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ePlDLKPK0ok6"},"source":["##3.Training start code  \n","This code creates an AI model with a CNN model"]},{"cell_type":"code","metadata":{"id":"8VhvWhjc5pIm","executionInfo":{"status":"ok","timestamp":1604223409771,"user_tz":-540,"elapsed":556638,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"209b5898-b3c5-4a7e-d830-c62dfa908810","colab":{"base_uri":"https://localhost:8080/"}},"source":["import os\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","import numpy as np\n","\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'original_trained_model.h5'\n","\n","# Specifying the image data folder\n","root_dir = \"./image/\"\n","directory = os.listdir(root_dir)\n","categories = [f for f in directory if os.path.isdir(os.path.join(root_dir, f))]\n","print(categories)\n","\n","num_classes = len(categories)\n","batch_size = 32\n","epochs = 15\n","\n","# Load model\n","x_train, x_test, y_train, y_test = np.load(\"./image/obj.npy\", allow_pickle=True)\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","model.summary()\n","\n","# Normalize the data\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('X_train shape:', x_train.shape)\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=(x_test, y_test),\n","          shuffle=True)\n","\n","# Save model and weights\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","model_path = os.path.join(save_dir, model_name)\n","model.save(model_path)\n","print('Saved trained model at %s ' % model_path)\n","\n","# Evaluate the model\n","score = model.evaluate(x_test, y_test)\n","print('loss=', score[0])\n","print('accuracy=', score[1])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch']\n","x_train shape: (6800, 224, 224, 3)\n","6800 train samples\n","1700 test samples\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 224, 224, 32)      896       \n","_________________________________________________________________\n","activation (Activation)      (None, 224, 224, 32)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 222, 222, 32)      9248      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 222, 222, 32)      0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 111, 111, 32)      0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 111, 111, 64)      18496     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 111, 111, 64)      0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 109, 109, 64)      36928     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 109, 109, 64)      0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 186624)            0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               95552000  \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 95,622,698\n","Trainable params: 95,622,698\n","Non-trainable params: 0\n","_________________________________________________________________\n","X_train shape: (6800, 224, 224, 3)\n","Epoch 1/15\n","  2/213 [..............................] - ETA: 13s - loss: 4.1152 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0355s vs `on_train_batch_end` time: 0.0947s). Check your callbacks.\n","213/213 [==============================] - 32s 151ms/step - loss: 1.7700 - accuracy: 0.4053 - val_loss: 1.2595 - val_accuracy: 0.6412\n","Epoch 2/15\n","213/213 [==============================] - 31s 146ms/step - loss: 1.0231 - accuracy: 0.6610 - val_loss: 0.7197 - val_accuracy: 0.7912\n","Epoch 3/15\n","213/213 [==============================] - 32s 148ms/step - loss: 0.6794 - accuracy: 0.7744 - val_loss: 0.4887 - val_accuracy: 0.8600\n","Epoch 4/15\n","213/213 [==============================] - 32s 149ms/step - loss: 0.4430 - accuracy: 0.8532 - val_loss: 0.4291 - val_accuracy: 0.8547\n","Epoch 5/15\n","213/213 [==============================] - 32s 149ms/step - loss: 0.3069 - accuracy: 0.9010 - val_loss: 0.2434 - val_accuracy: 0.9141\n","Epoch 6/15\n","213/213 [==============================] - 32s 150ms/step - loss: 0.2088 - accuracy: 0.9316 - val_loss: 0.1652 - val_accuracy: 0.9500\n","Epoch 7/15\n","213/213 [==============================] - 32s 151ms/step - loss: 0.1464 - accuracy: 0.9528 - val_loss: 0.1209 - val_accuracy: 0.9641\n","Epoch 8/15\n","213/213 [==============================] - 32s 151ms/step - loss: 0.1103 - accuracy: 0.9632 - val_loss: 0.1004 - val_accuracy: 0.9676\n","Epoch 9/15\n","213/213 [==============================] - 32s 151ms/step - loss: 0.0851 - accuracy: 0.9737 - val_loss: 0.0782 - val_accuracy: 0.9706\n","Epoch 10/15\n","213/213 [==============================] - 32s 151ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 0.0990 - val_accuracy: 0.9688\n","Epoch 11/15\n","213/213 [==============================] - 32s 151ms/step - loss: 0.0615 - accuracy: 0.9787 - val_loss: 0.0810 - val_accuracy: 0.9747\n","Epoch 12/15\n","213/213 [==============================] - 32s 151ms/step - loss: 0.0601 - accuracy: 0.9818 - val_loss: 0.0848 - val_accuracy: 0.9753\n","Epoch 13/15\n","213/213 [==============================] - 32s 150ms/step - loss: 0.0445 - accuracy: 0.9871 - val_loss: 0.0609 - val_accuracy: 0.9824\n","Epoch 14/15\n","213/213 [==============================] - 32s 151ms/step - loss: 0.0331 - accuracy: 0.9899 - val_loss: 0.0523 - val_accuracy: 0.9835\n","Epoch 15/15\n","213/213 [==============================] - 32s 150ms/step - loss: 0.0394 - accuracy: 0.9869 - val_loss: 0.0500 - val_accuracy: 0.9882\n","Saved trained model at /content/gdrive/My Drive/Easy-and-free-AI-learning/04_augmentation_image_recognition/saved_models/original_trained_model.h5 \n","54/54 [==============================] - 2s 32ms/step - loss: 0.0500 - accuracy: 0.9882\n","loss= 0.049957025796175\n","accuracy= 0.9882352948188782\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sjaobC8-05lc"},"source":["##4.predict start code\n","This code uses an AI model to classify image data.  \n","This code infers the image in the predict folder."]},{"cell_type":"code","metadata":{"id":"kSTthK7j7aUZ","executionInfo":{"status":"ok","timestamp":1604223432715,"user_tz":-540,"elapsed":579580,"user":{"displayName":"Hideki Shimizu","photoUrl":"","userId":"00933741023028792890"}},"outputId":"3e3427ce-d6ca-4bac-c1d4-06ea69f4ed5e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# coding:utf-8\n","import os\n","import re\n","import keras\n","import numpy as np\n","from keras.models import load_model\n","from keras.preprocessing.image import array_to_img, img_to_array,load_img\n","\n","from PIL import Image\n","\n","root_dir = \"./image/\"\n","directory = os.listdir(root_dir)\n","categories = [f for f in directory if os.path.isdir(os.path.join(root_dir, f))]\n","print(categories)\n","\n","num_classes = len(categories)\n","\n","image_size = 224\n","\n","def list_pictures(directory, ext='jpg|gif|png'):\n","    return [os.path.join(root, f)\n","            for root, _, files in os.walk(directory) for f in files\n","            if re.match(r'([\\w]+\\.(?:' + ext + '))', f.lower())]\n","\n","def convertCIFER10Data(image):\n","    img = image.astype('float32')\n","    img /= 255\n","    c = np.zeros(image_size*image_size*3).reshape((1,image_size,image_size,3))\n","    c[0] = img\n","    return c\n","\n","if __name__ == \"__main__\":\n","\n","    model = load_model('./saved_models/original_trained_model.h5')\n","    for picture in list_pictures('./predict/'):\n","\n","        image = Image.open(picture)\n","        image = image.resize((image_size, image_size))\n","        resize_frame = np.asarray(image)\n","        data = convertCIFER10Data(resize_frame)\n","\n","        ret = model.predict(data, batch_size=1)\n","\n","        print(\"----------------------------------------------\")\n","        print(\"I think...\")\n","\n","        bestnum = 0.0\n","        bestclass = 0\n","        for n in range(num_classes):\n","            print(\"[{}] : {}%\".format(categories[n], round(ret[0][n]*100,2)))\n","            if bestnum < ret[0][n]:\n","                bestnum = ret[0][n]\n","                bestclass = n\n","\n","        print(\"probability : {}%\".format( round(bestnum*100,2) ))\n","        print(picture,'→',\"AI think this is a [{}].\".format(categories[bestclass]))\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch']\n","----------------------------------------------\n","I think...\n","[camera] : 100.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 0.0%\n","[cup] : 0.0%\n","[dolphin] : 0.0%\n","[elephant] : 0.0%\n","[pizza] : 0.0%\n","[umbrella] : 0.0%\n","[watch] : 0.0%\n","probability : 100.0%\n","./predict/camera.jpg → AI think this is a [camera].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 99.13%\n","[chandelier] : 0.0%\n","[crayfish] : 0.0%\n","[cup] : 0.84%\n","[dolphin] : 0.0%\n","[elephant] : 0.0%\n","[pizza] : 0.0%\n","[umbrella] : 0.02%\n","[watch] : 0.0%\n","probability : 99.13%\n","./predict/chair.jpg → AI think this is a [chair].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 1.34%\n","[chandelier] : 98.65%\n","[crayfish] : 0.0%\n","[cup] : 0.0%\n","[dolphin] : 0.0%\n","[elephant] : 0.0%\n","[pizza] : 0.0%\n","[umbrella] : 0.0%\n","[watch] : 0.0%\n","probability : 98.65%\n","./predict/chandelier.jpg → AI think this is a [chandelier].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 97.62%\n","[cup] : 0.0%\n","[dolphin] : 0.0%\n","[elephant] : 2.37%\n","[pizza] : 0.0%\n","[umbrella] : 0.0%\n","[watch] : 0.0%\n","probability : 97.62%\n","./predict/crayfish.jpg → AI think this is a [crayfish].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 0.0%\n","[cup] : 100.0%\n","[dolphin] : 0.0%\n","[elephant] : 0.0%\n","[pizza] : 0.0%\n","[umbrella] : 0.0%\n","[watch] : 0.0%\n","probability : 100.0%\n","./predict/cup.jpg → AI think this is a [cup].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 0.0%\n","[cup] : 0.0%\n","[dolphin] : 100.0%\n","[elephant] : 0.0%\n","[pizza] : 0.0%\n","[umbrella] : 0.0%\n","[watch] : 0.0%\n","probability : 100.0%\n","./predict/dolphin.jpg → AI think this is a [dolphin].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 0.01%\n","[cup] : 0.0%\n","[dolphin] : 0.0%\n","[elephant] : 99.99%\n","[pizza] : 0.0%\n","[umbrella] : 0.0%\n","[watch] : 0.0%\n","probability : 99.99%\n","./predict/elephant.jpg → AI think this is a [elephant].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 0.0%\n","[cup] : 0.0%\n","[dolphin] : 0.0%\n","[elephant] : 0.0%\n","[pizza] : 100.0%\n","[umbrella] : 0.0%\n","[watch] : 0.0%\n","probability : 100.0%\n","./predict/pizza.jpg → AI think this is a [pizza].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 0.0%\n","[cup] : 0.0%\n","[dolphin] : 0.0%\n","[elephant] : 0.0%\n","[pizza] : 0.0%\n","[umbrella] : 100.0%\n","[watch] : 0.0%\n","probability : 100.0%\n","./predict/umbrella.jpg → AI think this is a [umbrella].\n","----------------------------------------------\n","I think...\n","[camera] : 0.0%\n","[chair] : 0.0%\n","[chandelier] : 0.0%\n","[crayfish] : 0.0%\n","[cup] : 0.0%\n","[dolphin] : 0.0%\n","[elephant] : 0.0%\n","[pizza] : 0.0%\n","[umbrella] : 0.0%\n","[watch] : 100.0%\n","probability : 100.0%\n","./predict/watch.jpg → AI think this is a [watch].\n"],"name":"stdout"}]}]}