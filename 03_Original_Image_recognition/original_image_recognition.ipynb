{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_image_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_GkibcbD930"
      },
      "source": [
        "# **Teaching materials for AI beginners**  \n",
        "**Original image recognition**  \n",
        "Let's create an AI model with the prepared image.\n",
        "Once you can do this, you will be able to create your own image classification model.  \n",
        "We prepared 10 classes of 50 images for each class.  \n",
        "'camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch'  \n",
        "The more images you have, the higher the accuracy.  \n",
        "You can also try changing to the collected image.\n",
        "Just put the images in a folder.\n",
        "It's very easy. Try it with your own image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csAW4DCxFMtk"
      },
      "source": [
        "##1.Development environment preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpQazSrIxkMD"
      },
      "source": [
        "###1-1.Connect to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5winc0172fJa",
        "outputId": "4a5c5c7b-fd7f-4346-ba14-02f606f91f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "426PZy36FYj2"
      },
      "source": [
        "###1-2.Go to My Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fzfjaol3WPF",
        "outputId": "8b86a100-8dd2-49d4-c280-b8790309a3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My\\ Drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nAwjalfFkaw"
      },
      "source": [
        "###1-3.Download the code from github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0v4WDGf4FkO",
        "outputId": "bc059dc4-e749-43d8-acfe-681631d6158b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "!git clone https://github.com/ai-coodinator/Easy-and-free-AI-learning.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Easy-and-free-AI-learning'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 757 (delta 2), reused 0 (delta 0), pack-reused 747\u001b[K\n",
            "Receiving objects: 100% (757/757), 7.51 MiB | 8.61 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "Checking out files: 100% (532/532), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPtl8d5UFtUg"
      },
      "source": [
        "##1-4.Change to the downloaded directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4bhPxFs4JHx",
        "outputId": "9876c122-e388-4f2f-cba9-17d0023af4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Easy-and-free-AI-learning/03_Original_Image_recognition/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Easy-and-free-AI-learning/03_Original_Image_recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad08kRkN275z"
      },
      "source": [
        "##1-5.Confirmation of GPU to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M0hIVoy20UN",
        "outputId": "ed78caa3-5b4b-4597-e119-c90c7c6df8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Oct 26 11:54:51 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5gmIjCyzuoo"
      },
      "source": [
        "##2.Data creation for learning  \n",
        "This code transforms the prepared image data into a single training dataset.  \n",
        "If you want to change or add training data, make the folder a class and place it in the Image folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzyaQx424xU0",
        "outputId": "3ed7c879-f032-44a7-b0c0-51a5361d5b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "\n",
        "# read image\n",
        "root_dir = \"./image/\"\n",
        "directory = os.listdir(root_dir)\n",
        "categories = [f for f in directory if os.path.isdir(os.path.join(root_dir, f))]\n",
        "print(categories)\n",
        "\n",
        "num_classes = len(categories)\n",
        "# resize\n",
        "image_size = 224\n",
        "\n",
        "# make image dataset\n",
        "X = [] # image\n",
        "Y = [] # label\n",
        "\n",
        "# read image\n",
        "for idx, cat in enumerate(categories):\n",
        "\n",
        "    label = [0 for i in range(num_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = root_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.jpg\")\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_size, image_size))\n",
        "        data = np.asarray(img)\n",
        "        X.append(data)\n",
        "        Y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# make npy\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X, Y, test_size=0.2)\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"./image/\" + \"obj.npy\", xy)\n",
        "\n",
        "print(\"ok,\", len(X_train), len(X_test))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch']\n",
            "ok, 400 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePlDLKPK0ok6"
      },
      "source": [
        "##3.Training start code  \n",
        "This code creates an AI model with a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VhvWhjc5pIm",
        "outputId": "71da4d8f-430a-4e6e-ebc5-b7f95ce35c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "import numpy as np\n",
        "\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'original_trained_model.h5'\n",
        "\n",
        "# Specifying the image data folder\n",
        "root_dir = \"./image/\"\n",
        "directory = os.listdir(root_dir)\n",
        "categories = [f for f in directory if os.path.isdir(os.path.join(root_dir, f))]\n",
        "print(categories)\n",
        "\n",
        "num_classes = len(categories)\n",
        "batch_size = 32\n",
        "epochs = 15\n",
        "\n",
        "# Load model\n",
        "x_train, x_test, y_train, y_test = np.load(\"./image/obj.npy\", allow_pickle=True)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('X_train shape:', x_train.shape)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss=', score[0])\n",
        "print('accuracy=', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch']\n",
            "x_train shape: (400, 224, 224, 3)\n",
            "400 train samples\n",
            "100 test samples\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 224, 224, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 222, 222, 32)      9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 222, 222, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 111, 111, 64)      18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 111, 111, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 109, 109, 64)      36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 109, 109, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 186624)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               95552000  \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 95,622,698\n",
            "Trainable params: 95,622,698\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "X_train shape: (400, 224, 224, 3)\n",
            "Epoch 1/15\n",
            " 2/13 [===>..........................] - ETA: 0s - loss: 4.3340 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0279s vs `on_train_batch_end` time: 0.0476s). Check your callbacks.\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 3.1927 - accuracy: 0.1425 - val_loss: 2.2997 - val_accuracy: 0.1100\n",
            "Epoch 2/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 2.1447 - accuracy: 0.2600 - val_loss: 2.1009 - val_accuracy: 0.2700\n",
            "Epoch 3/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.9587 - accuracy: 0.3150 - val_loss: 2.0709 - val_accuracy: 0.3000\n",
            "Epoch 4/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.8671 - accuracy: 0.3800 - val_loss: 1.9800 - val_accuracy: 0.3500\n",
            "Epoch 5/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.7574 - accuracy: 0.4325 - val_loss: 1.9162 - val_accuracy: 0.3000\n",
            "Epoch 6/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.5837 - accuracy: 0.4750 - val_loss: 1.7980 - val_accuracy: 0.4000\n",
            "Epoch 7/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.4599 - accuracy: 0.5225 - val_loss: 1.7591 - val_accuracy: 0.4300\n",
            "Epoch 8/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.2740 - accuracy: 0.6025 - val_loss: 1.6551 - val_accuracy: 0.4100\n",
            "Epoch 9/15\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.1472 - accuracy: 0.6325 - val_loss: 1.6293 - val_accuracy: 0.4800\n",
            "Epoch 10/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.0331 - accuracy: 0.6700 - val_loss: 1.5062 - val_accuracy: 0.5600\n",
            "Epoch 11/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.9172 - accuracy: 0.6950 - val_loss: 1.5610 - val_accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.8148 - accuracy: 0.7425 - val_loss: 1.4961 - val_accuracy: 0.5200\n",
            "Epoch 13/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7254 - accuracy: 0.7775 - val_loss: 1.5134 - val_accuracy: 0.5200\n",
            "Epoch 14/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6312 - accuracy: 0.8050 - val_loss: 1.4808 - val_accuracy: 0.5000\n",
            "Epoch 15/15\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5069 - accuracy: 0.8625 - val_loss: 1.4086 - val_accuracy: 0.6000\n",
            "Saved trained model at /content/gdrive/My Drive/Easy-and-free-AI-learning/03_Original_Image_recognition/saved_models/original_trained_model.h5 \n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.4086 - accuracy: 0.6000\n",
            "loss= 1.4085925817489624\n",
            "accuracy= 0.6000000238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjaobC8-05lc"
      },
      "source": [
        "##4.predict start code\n",
        "This code uses an AI model to classify image data.  \n",
        "This code infers the image in the predict folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSTthK7j7aUZ",
        "outputId": "52747836-3980-45a5-a65d-934ce88cbdad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# coding:utf-8\n",
        "import os\n",
        "import re\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array,load_img\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "root_dir = \"./image/\"\n",
        "directory = os.listdir(root_dir)\n",
        "categories = [f for f in directory if os.path.isdir(os.path.join(root_dir, f))]\n",
        "print(categories)\n",
        "\n",
        "num_classes = len(categories)\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "def list_pictures(directory, ext='jpg|gif|png'):\n",
        "    return [os.path.join(root, f)\n",
        "            for root, _, files in os.walk(directory) for f in files\n",
        "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f.lower())]\n",
        "\n",
        "def convertCIFER10Data(image):\n",
        "    img = image.astype('float32')\n",
        "    img /= 255\n",
        "    c = np.zeros(image_size*image_size*3).reshape((1,image_size,image_size,3))\n",
        "    c[0] = img\n",
        "    return c\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model = load_model('./saved_models/original_trained_model.h5')\n",
        "    for picture in list_pictures('./predict/'):\n",
        "\n",
        "        image = Image.open(picture)\n",
        "        image = image.resize((image_size, image_size))\n",
        "        resize_frame = np.asarray(image)\n",
        "        data = convertCIFER10Data(resize_frame)\n",
        "\n",
        "        ret = model.predict(data, batch_size=1)\n",
        "\n",
        "        print(\"----------------------------------------------\")\n",
        "        print(\"I think...\")\n",
        "\n",
        "        bestnum = 0.0\n",
        "        bestclass = 0\n",
        "        for n in range(num_classes):\n",
        "            print(\"[{}] : {}%\".format(categories[n], round(ret[0][n]*100,2)))\n",
        "            if bestnum < ret[0][n]:\n",
        "                bestnum = ret[0][n]\n",
        "                bestclass = n\n",
        "\n",
        "        print(\"probability : {}%\".format( round(bestnum*100,2) ))\n",
        "        print(picture,'→',\"AI think this is a [{}].\".format(categories[bestclass]))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['camera', 'chair', 'chandelier', 'crayfish', 'cup', 'dolphin', 'elephant', 'pizza', 'umbrella', 'watch']\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 73.91%\n",
            "[chair] : 0.74%\n",
            "[chandelier] : 0.24%\n",
            "[crayfish] : 2.64%\n",
            "[cup] : 1.56%\n",
            "[dolphin] : 1.87%\n",
            "[elephant] : 7.39%\n",
            "[pizza] : 0.64%\n",
            "[umbrella] : 1.23%\n",
            "[watch] : 9.78%\n",
            "probability : 73.91%\n",
            "./predict/camera.jpg → AI think this is a [camera].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 3.39%\n",
            "[chair] : 7.47%\n",
            "[chandelier] : 12.19%\n",
            "[crayfish] : 12.63%\n",
            "[cup] : 38.89%\n",
            "[dolphin] : 2.96%\n",
            "[elephant] : 6.62%\n",
            "[pizza] : 2.4%\n",
            "[umbrella] : 11.29%\n",
            "[watch] : 2.17%\n",
            "probability : 38.89%\n",
            "./predict/chair.jpg → AI think this is a [cup].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 0.05%\n",
            "[chair] : 14.2%\n",
            "[chandelier] : 48.22%\n",
            "[crayfish] : 4.85%\n",
            "[cup] : 5.83%\n",
            "[dolphin] : 0.12%\n",
            "[elephant] : 0.57%\n",
            "[pizza] : 16.08%\n",
            "[umbrella] : 0.35%\n",
            "[watch] : 9.72%\n",
            "probability : 48.22%\n",
            "./predict/chandelier.jpg → AI think this is a [chandelier].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 6.27%\n",
            "[chair] : 7.51%\n",
            "[chandelier] : 5.39%\n",
            "[crayfish] : 15.21%\n",
            "[cup] : 6.71%\n",
            "[dolphin] : 2.54%\n",
            "[elephant] : 25.41%\n",
            "[pizza] : 15.6%\n",
            "[umbrella] : 4.06%\n",
            "[watch] : 11.28%\n",
            "probability : 25.41%\n",
            "./predict/crayfish.jpg → AI think this is a [elephant].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 1.92%\n",
            "[chair] : 3.05%\n",
            "[chandelier] : 3.62%\n",
            "[crayfish] : 7.15%\n",
            "[cup] : 69.88%\n",
            "[dolphin] : 1.76%\n",
            "[elephant] : 2.6%\n",
            "[pizza] : 1.21%\n",
            "[umbrella] : 5.38%\n",
            "[watch] : 3.45%\n",
            "probability : 69.88%\n",
            "./predict/cup.jpg → AI think this is a [cup].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 0.93%\n",
            "[chair] : 2.01%\n",
            "[chandelier] : 1.12%\n",
            "[crayfish] : 14.75%\n",
            "[cup] : 3.21%\n",
            "[dolphin] : 65.82%\n",
            "[elephant] : 7.83%\n",
            "[pizza] : 0.27%\n",
            "[umbrella] : 2.27%\n",
            "[watch] : 1.8%\n",
            "probability : 65.82%\n",
            "./predict/dolphin.jpg → AI think this is a [dolphin].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 0.15%\n",
            "[chair] : 0.26%\n",
            "[chandelier] : 1.22%\n",
            "[crayfish] : 11.36%\n",
            "[cup] : 2.63%\n",
            "[dolphin] : 0.52%\n",
            "[elephant] : 79.18%\n",
            "[pizza] : 3.41%\n",
            "[umbrella] : 1.09%\n",
            "[watch] : 0.19%\n",
            "probability : 79.18%\n",
            "./predict/elephant.jpg → AI think this is a [elephant].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 0.06%\n",
            "[chair] : 1.27%\n",
            "[chandelier] : 0.49%\n",
            "[crayfish] : 15.41%\n",
            "[cup] : 3.01%\n",
            "[dolphin] : 0.11%\n",
            "[elephant] : 2.05%\n",
            "[pizza] : 74.01%\n",
            "[umbrella] : 1.35%\n",
            "[watch] : 2.24%\n",
            "probability : 74.01%\n",
            "./predict/pizza.jpg → AI think this is a [pizza].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 0.01%\n",
            "[chair] : 1.07%\n",
            "[chandelier] : 0.04%\n",
            "[crayfish] : 16.26%\n",
            "[cup] : 0.99%\n",
            "[dolphin] : 0.17%\n",
            "[elephant] : 13.24%\n",
            "[pizza] : 64.31%\n",
            "[umbrella] : 3.9%\n",
            "[watch] : 0.0%\n",
            "probability : 64.31%\n",
            "./predict/umbrella.jpg → AI think this is a [pizza].\n",
            "----------------------------------------------\n",
            "I think...\n",
            "[camera] : 9.27%\n",
            "[chair] : 1.58%\n",
            "[chandelier] : 0.02%\n",
            "[crayfish] : 2.54%\n",
            "[cup] : 3.4%\n",
            "[dolphin] : 0.24%\n",
            "[elephant] : 0.44%\n",
            "[pizza] : 0.68%\n",
            "[umbrella] : 3.95%\n",
            "[watch] : 77.88%\n",
            "probability : 77.88%\n",
            "./predict/watch.jpg → AI think this is a [watch].\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}